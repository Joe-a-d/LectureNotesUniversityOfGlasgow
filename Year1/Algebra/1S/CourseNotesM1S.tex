
%% CLASS MANUAL FOUND at http://blog.poormansmath.net/latex-class-for-lecture-notes/ %%
%% CLASS AUTHOR Stefano Maggiolo %%
\documentclass[english,course]{Notes}

\title{MATHEMATICS 1S}
\subject{Mathematics}
\author{Joao Almeida-Domingues}
\email{2334590D@student.gla.ac.uk}
\speaker{Dr. Andrew Wilson}
\date{07}{01}{2019}
\dateend{24}{05}{2019}
\place{University of Glasgow}

\usepackage[backend=biber, style=reading]{biblatex}
\bibliography{M1Sbiblio}



 %%%%% GENERAL MATHEMATICAL NOTATION SHORTCUTS %%%%%
 
\newcommand{\n}{\mathbb{N}}
\newcommand{\z}{\mathbb{Z}}
\newcommand{\q}{\mathbb{Q}}
\newcommand{\cx}{\mathbb{C}}
\newcommand{\real}{\mathbb{R}}
\newcommand{\field}{\mathbb{F}}
\newcommand{\ita}[1]{\textit{#1}}
\newcommand{\oneton}{\{1,2,3,...,n\}}
\newcommand\ef{\ita{f} }
\newcommand\inv[1]{#1^{-1}}
\newcommand\setb[1]{\{#1\}}
\newcommand\en{\ita{n }}
\newcommand\comb[2]{^{#1}C_{#2}}
\newcommand\perm[2]{^{#1}P_{#2}}

%\renewcommand\qedsymbol{QED} %to use QED instead of square


%%%%%%%%%%%%%%%%PACKAGES%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{lipsum}  
\usepackage{amsmath,amsthm,amssymb,graphicx,mathtools,tikz,pgfplots,minibox} %maths
\pgfplotsset{compat=1.16}
\usepackage{hyperref,framed,color,fancybox} %layout
% framed :  \begin{shaded,frame,snugshade or leftbar} \definecolor{shadecolor}{rgb}{XYZ} to change color
%fancybox: \shadowbox,ovalbox or doublebox
%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%CLASS SHORTCUTS%%%%
%\lecture{day}{month}{year} for margin note 
%\begin{theorem} sdfsdf\end{theorem}
%\begin{proposition} dfsdfs\end{proposition}
%\begin{lemma} dsfsd \end{lemma} %lem
%\begin{corollary} f ffew \end{corollary}
%\begin{definition} fwewef w \end{definition} %defn
%\begin{example} feww e\end{example} %ex
%\begin{exercise} wefwe \end{exercise}
%\begin{remark} wef we \end{remark} %rem
%\begin{fact} wefe \end{fact}
%\begin{problem} wef ew \end{problem}
%\begin{conjecture} ewfew \end{conjecture}
%\begin{claim} few w \end{claim}
%\begin{notation} fewf \end{notation} %nota

\begin{document}
\newpage

\section{Vectors}

\subsection{Generalities}

\lecture{07}{01}{2019}

\defn{A scalar}{is a one-component quantity that is invariant under rotations of the coordinate system, which describes the magnitude of something}

\defn{A vector}{ is a two-component quantity, with magnitude (a positive real number) and direction}

\rem{If a vector has both a magnitude and direction of $0$, then that vector is  the zero vector. The zero vector can be thought as having no direction, or all directions}

\defn{Equality:}{ Two vectors are equal if they have the same magnitude and the same direction\label{def:eq}}

\rem{Every vector is unique}

\proofs{ Let $\vc{u}, \vc{v}$ be two vectors with magnitude $\lambda$ and the same direction. Hence by \ref{def:eq} , $\vc{u} = \vc{v}$}


\nota{ Generally, in printed text $\overrightarrow{v} \text{ or } \ \vc{v}$. Handwritten \underline{$v$}. Magnitude $\vc{|v|}$}

\defn{Unit vector}{is a vector of magnitude 1. There is exactly one for any given direction}
\nota{Generally, for a given vector $\vc{v} \ , \ \hat{\vc{v}}$}

\prop{Parallelogram }{$\overrightarrow{AB} = \overrightarrow{DC}$\ , i.e Traversing left-up is the same as up-right}
\proofs{It follows from the fact that the opposite sides of a parallelogram are parallel and of equal length. Hence they are equal, by \ref{def:eq}}

\prop{Negative vectors }{$\overrightarrow{AB} = u \iff \overrightarrow{BA} = -u$}
\proofs{It follows from the fact that they have the same magnitude but opposite directions}

\prop{Zero vector }{$\overrightarrow{AA} = 0$}
\proofs{For any point $A, |AA| = 0$ and so $\overrightarrow{AA} = 0$}

\subsection{Addition and Scalar Multiplication}

\defn{Addition}{Let $\vc{u} = \overrightarrow{PQ} \ , \ \vc{v} = \overrightarrow{QR}. \vc{u} + \vc{v} = \overrightarrow{PR}$. \ita{nose-to-tail}}

\rem{As per usual subtraction is simply, $\vc{u} + (-\vc{v})$}

\defn{Scalar Multiplication}{For a vector $\vc{u}$, and a scalar $\lambda$. $\lambda\vc{u}$ scales the vector's magnitude  by $\lambda$, and if $\lambda<0$ inverts its direction}

\lecture{8}{01}{2019}
\subsubsection{Properties of Addition and Multiplication}
\prop{Commutative }{$\vc{u} + \vc{v} = \vc{v} + \vc{u}$}
\proofs{
\begin{align*}
	 \vc{u} + \vc{v} & = [u_1, u_2 , \dots , u_n] + [v_1 , v_2 , \dots , u_n] \\
	 & = [u_1 + v_1 , u_2 + v_2 , \dots , u_n + v_n] \text{  \ita{vector addition}} \\
	 & = [v_1 + u_1, v_2 + u_2 , \dots , v_n + u_n] \text{  \ita{commutative adition of real numbers}} \\
	 & = [v_1 , v_2 , \dots , v_n] + [u_1, u_2 , \dots , u_n] \\
	 & = \vc{v} + \vc{u}
\end{align*}
}


\prop{Associative }{$(\vc{u} + \vc{v}) + \vc{w} = \vc{u} + (\vc{v} + \vc{w})$}
\proofs{
\begin{align*}
	(\vc{u} + \vc{v}) + \vc{w} & = ([u_1, u_2 , \dots , u_n] + [v_1 , v_2 , \dots , v_n]) + [w_1 , w_2 , \dots , w_n] \\
	 & = [u_1 + v_1 , u_2 + v_2 , \dots , u_n + v_n]  + [w_1 , w_2 , \dots , w_n]   \mathbf(1.10) \\
	 & = [(u_1 + v_1) + w_1, (u_2 + v_2) + w_2, \dots , (u_n + v_n) + w_n] \text{  \ita{commutative property of scalars}} \\
	 & = [u_1 + (v_1 + w_1), u_2 + ( v_2 + w_2), \dots , u_n + (v_n + w_n)] \text{  \ita{associative addition of real numbers}} \\
	 & = [u_1 , u_2 , \dots , u_n] + [v_1 + w_1 , v_2 + w_2 , \dots , v_n + w_n]  \\
	 & = \vc{u} + \vc{v} + \vc{w}
\end{align*}
}

\prop{Distributive }{$\lambda(\vc{u} + \vc{v}) = \lambda\vc{u} +\lambda\vc{v}$}
\proofs{
\begin{align*}
	\lambda(\vc{u} + \vc{v}) & = \lambda([u_1 + v_1 , u_2 + v_2 , \dots , u_n + v_n]   \text{  \ita{vector addition}} \\ 
	& = [\lambda(u_1 + v_1) , \lambda(u_2 + v_2) , \dots , \lambda(u_n + v_n)] \text{  \ita{scalar multiplication} }\\
	& = [\lambda u_1 + \lambda v_1 , \lambda u_2 + \lambda v_2 , \dots , \lambda u_n + \lambda v_n] \text{  \ita{distributive for real numbers}} \\
	& = \lambda\vc{u} + \lambda\vc{v}
\end{align*}
}

\newpage
\proofs{ \ita{2 , by a diagram} \\

Let $\vc{u} , \vc{v}$ be two non-zero vectors, and A, B, C be 3 distinct points. Then:

\begin{tikzpicture}
\centering
\draw (0,0) node[anchor=north]{$O$}
  -- (2,0) node[anchor=north]{$A$}
  -- (2,2) node[anchor=south]{$B$}
    -- cycle;
    \draw
  -- (0.5,1) node[anchor=south]{$\vc{u} + \vc{v}$}
  -- (2.2,0.5) node[anchor=south]{$\vc{u}$}
  -- (1,0) node[anchor=south]{$\vc{v}$};


\draw (0,0) node[anchor=north]{$O$}
  -- (4,0) node[anchor=north]{$A'$}
  -- (4,4) node[anchor=south]{$B'$}
  -- cycle;
  \draw
    -- (2.5,3) node[anchor=south]{$\lambda(\vc{u} + \vc{v})$}
  -- (4.2,2) node[anchor=south]{$\lambda\vc{u}$}
  -- (3,0) node[anchor=south]{$\lambda\vc{v}$};
  \end{tikzpicture}

Let the "prime" triangle represent a $\lambda$ fold enlargement of the original triangle representing the original vectors and their addition. Hence we have that,

\begin{align*}
OB' = \lambda(\vc{u} + \vc{v}) & = OA' + A'B' \\
& = \lambda\vc{v} + \lambda\vc{u}
\end{align*}
}







\subsection{Parallel and Position vectors}

\defn{Parallel:}{ Let $\vc{u} \ , \ \vc{v}$ be two non-zero vectors. Then, 
$\vc{v}$ is parallel to $\vc{u}$ \ita{iff} $\vc{v} = \lambda\vc{u}$ (i.e. if they share the same or opposite directions) and $\hat{\vc{u}} = \frac{1}{|\vc{u}|}\vc{u}$}

\nota{$\vc{u} \parallel \vc{v}$}

\rem{The non-zero vector is parallel to all vectors}

\proofs{ The first part of the definition is self-evident as any scalar multiple of a vector will only alter its magnitude and/or reverse its direction. For the second part, we have that:

$$ \bigg|\frac{1}{|\vc{u}|}\vc{u}\bigg| = \frac{1}{|\vc{u}|}|\vc{u}| = 1 $$

Hence, we've shown that $\frac{1}{|\vc{u}|}|\vc{u}|$ is a unit vector of $\vc{u}$, which means that it only varies in magnitude, and is therefore parallel.
}

\defn{Position:}{Let $O$ denote the origin, the vector from $O$ to any point $P$ ($\overrightarrow{OP}$) is called the position vector. For any points  $A \text{ and } B , \overrightarrow{ AB } = \vc{b} -  \vc{a}$}

\nota{ $\vc{r}_p$}

\proofs{ \\

\begin{tikzpicture}
\centering
\draw (0,0) node[anchor=north]{$A$}
  -- (2,0) node[anchor=north]{$O$}
  -- (2,2) node[anchor=south]{$B$}
  -- cycle;
\end{tikzpicture} 
\ \ \ \ \ \  $
\begin{aligned} \overrightarrow{ A B } & = \overrightarrow { A O } + \overrightarrow { O B } \\ & = ( - \mathbf { a } ) + \mathbf { b } \\ & = \mathbf { b } - \mathbf { a } \end{aligned}$
}

\lecture{09}{01}{2019}
\subsection{Collinearity and the section formula}

\defn{Collinear}{points lie on a straight line}

\rem{One can test wether points are collinear by finding if their directed line segments, i.e. the vector formed starting at a point and ending at the other, are parallel.}

\ex{ Let $\overrightarrow{AB} = \vc{u} , \overrightarrow{BC} = 2\vc{u} , \overrightarrow{AC} = \vc{u} + \vc{2u} = \vc{3u}$. Hence they are all parallel to $\vc{u}$, it follows then that they are collinear.}

\rem{ $$ AB : BC = \beta : \alpha \implies \alpha \overrightarrow{AB} = \overrightarrow{BC} $$ }

Setting $\lambda = \frac{\beta}{\alpha}$,

$$ \overrightarrow{AB} = \lambda\overrightarrow{BC} \ \ \ AB : BC = \lambda : 1 $$

\par{Since $A , B \text{ and } C$ are collinear, we can deduce the distance between the points using their ratio \Big($\lambda = \tfrac{|AB|}{|BC|}$\Big). Furthermore, for $\lambda > 0 $ we have that the vectors have the same direction,  hence $B$ lies between $A$ and $C$. Note however that this is not true for $\lambda < 0$} 


\begin{tikzpicture}
\draw (0,0) node[anchor=north]{$A$}
  -- (2,0) node[anchor=north]{$B$}
  node[pos=0.5]{$>$}
  -- (5,0) node[anchor=north]{$C$}
    node[pos=0.5]{$>$}
  	(6,0) node[anchor=north]{$A$}
  -- (8,0) node[anchor=north]{$C$}
  node[pos=0.5]{$>$}
  node[pos=1.5]{$<$}
  -- (10,0) node[anchor=north]{$B$};
   
\end{tikzpicture} x

\prop{Section Formula \label{secForm}}{ Let $A, B \text{ and } P$ be collinear points, s.t:

$$ AP : PB = m : n $$

Then, $P$ has position vector $$ \vc{p} = \frac{m\vc{b} + n\vc{a}}{m + n} $$

\begin{tikzpicture}
\draw (2,0) -- (10,0)
(4,0) node[anchor=north]{$A$}
(5,0) node[anchor=south]{$m$}
(7,0) node[anchor=north]{$P$}
(8,0) node[anchor=south]{$n$}
(9,0) node[anchor=north]{$B$};

\end{tikzpicture}
 }

\proofs{ 
\begin{align*}
n\overrightarrow{AP} &= m \overrightarrow{PB} \\
n(\vc{p} - \vc{a}) &= m(\vc{b} -\vc{p}) \\
(m+n)\vc{p} &= m\vc{b} + n\vc{a} \\
\vc{p} &= \frac{m\vc{b} + n\vc{a}}{m + n}
\end{align*}}

\begin{corollary}{The midpoint of $AB$ has position vector $\tfrac{1}{2}(\vc{a} + \vc{b})$ \mymarginpar{special case of \ref{secForm}, where $m = n = 1$}}\end{corollary}

\mymarginpar{TODO: Applications of  the section formula}


\lecture{14}{01}{19}
\subsection{Scalar/Dot Product}

\defn{Scalar Product}{ of two unit vectors is the cosine of the angle between them. We obtain the scalar product of any two non-zero, non-unit vectors by scaling them by their magnitudes.}

\nota{$ \vc{u} \cdot \vc{v}$}

$$ \hat{\vc{u}} \cdot \hat{\vc{v}} = \cos\theta \ \ \ \& \ \ \  \vc{u} \cdot \vc{v} = |\vc{u}| |\vc{v}| \cos\theta $$

\rem{Note that $\theta \in [0,\pi]$}

\rem{If one of the vectors is a zero vector their scalar product is $0$}

\prop{For any vector $\vc{u}$: $$ \vc{u} \cdot \vc{u} = |u|^2$$}

\proofs{ It follows from the fact that $\theta = 0 , \cos\theta = 1$. Hence: 
	$$  \vc{u} \cdot \vc{u} = |\vc{u}| |\vc{u}| (1) =  |u|^2 $$}

\prop{Two non-zero vectors are perpendicular if their scalar product is $0$}

\proofs{ $\vc{u} \bot \vc{v} \iff \theta = \tfrac{\pi}{2}$. Hence, $\cos\theta = 0$. Therefore: \\

$ \vc{u} \cdot \vc{v} = |\vc{u}| |\vc{v}| (0) = 0$}

\newpage\subsubsection{Properties of Scalar Products}

\prop{Commutative }{$\vc{u} + \vc{v} = \vc{v} + \vc{u}$}

\proofs{ 
\begin{align*}
\vc{u} \cdot \vc{v} &= u_1v_1 + u_2v_2 + \dots + u_nv_n \\
&= v_1u_1 + v_2u_2 + \dots + v_nu_n \ \ \ita{(commutative multiplication of real numbers)}\\
&= \vc{v}\cdot\vc{u}
\end{align*}}

\prop{Distributive  }{ $\vc { u } \cdot ( \vc { v } + \vc { w } ) = \vc { u } \cdot \vc { v } + \vc { u } \cdot \vc { w }$}

\proofs{
\begin{align*}
\vc{u} \cdot (\vc{v} + \vc{w}) &= (u_1,u_2,\cdots,u_n) \cdot (v_1+w_1 , v_2+w_2 , \dots , v_n+w_n) \ \ \ita{(vector addition)} \\
&= u_1(v_1+w_1) + u_2(v_2+w_2) + \dots +  u_n(v_n+w_n) \ \  \ita{(vector multiplication)} \\
&= (u_1v_1 + u_1w_1) + (u_2v_2 + u_2w_2) + \dots +  (u_nv_n + u_nw_n) \ \ \ita{(scalar multiplication)} \\
&= (u_1v_1 + u_2v_2 + \dots + u_nv_n) + (u_1w_1 + u_2w_2 + \dots + u_nw_n) \ \ \ita{(associativity of real numbers)} \\
&= \vc{u}\vc{v} + \vc{u}\vc{w}
\end{align*}
}

\prop{NON-Associative}{}
\proofs{$\vc{u} \cdot (\vc{v} \cdot \vc{w})$ is an invalid expression, since the dot product returns a scalar and we cannot perform the dot product between a scalar and a vector}

\subsection{Normal to a Plane}

\defn{A normal to a plane}{ is a vector that is at right-angles to every vector contained within it}

\rem{Every plane has two normals, one pointing "upwards" and another "downwards"}

\rem{Note that there are infinitely many planes, lying parallel to one another~\mymarginpar{Think of stack}. Hence, to define a plane one needs to know its normal and a point within it.}

\defn{Plane~\label{vectors:plane}}{We observe that a point p lies on P, given a normal $\vc{n}$, \ita{iff} the dot product between the directed line segment on the plane and the normal is $0$.  $$ P = \text{\{points P } |  \ \vc{n} \cdot \overrightarrow{pP} = 0 \} $$}

\newpage
\lecture{15}{01}{2019}

\subsection{Cross Product}

\par{To start exploring the nature of the cross product of two 3D vectors, we first note that the two vectors form an area. We see this often exemplified by the parallelogram rule. Now let $A(\theta)$ represent the area demarcated by this parallelogram. This function of $\theta$ has its maximum when $\theta = \tfrac{\pi}{2}$ , i.e. when the parallelogram is a square, and its minimum when $\theta =  0$ , i.e. $\vc{u}$ and $\vc{v}$ are parallel.}

$$A ( \theta ) = \left\{ \begin{array} { l l } { 0 } & { \text { when } \theta = 0 } \\ { | \mathbf { u } | | \mathbf { v } | } & { \text { when } \theta = \frac { \pi } { 2 } } \\ { 0 } & { \text { when } \theta = \pi } \end{array} \right.$$

\defn{Cross Product}{$\vc{u} \times \vc{v}$ is a vector with magnitude $|\vc{u}||\vc{v}|\sin\theta$*\mymarginpar{*this is just the area of the parallelogram} and direction given by the normal~\ref{cross:rhr} of the plane on which the parallelogram lies}

\defn{Righ-Hand Rule~\label{cross:rhr}}{Convention used to fix the direction of the parallelogram uniquely \scriptsize{(remember that this is because it could point "upwards" or "downwards")}. \normalsize By putting the index finger parallel to the palm, and orientating the thumb and first finger in the directions of $\vc{u} , \vc{v}$. The index finger gives us the fixed direction}

\prop{Parallelism Criterion}{ Two non-zero vectors are parallel \ita{iff}  \\ $ \vc{u} \times \vc{v} = 0$}

\proofs{This follows from the fact that two vectors are parallel if $\theta = 0$ or $\theta = \pi$ , either way $\sin\theta = 0$ , therefore $|\vc{u}||\vc{v}|\sin\theta = 0$}

\rem{Note how for the dot product we start by looking at the parallelism of two vectors, and get a criterion for their perpendicularity. Whilst for the cross product the opposite is true.}

\subsubsection{Properties of the Cross Product}

\rem{Note that the cross product is only valid up to 3D}

\prop{Anti-Commutative}{\ \ \ $\vc{a} \times \vc{b} \neq \vc{b} \times \vc{a}$ $$\vc{a} \times \vc{b} = - ( \vc{b} \times \vc{a})$$}

\proofs{For non-parallel vectors, the result follows from the fact that even though the magnitude remains unchanged*~\mymarginpar{*just like in the dot product} , i.e. $|\vc{u} \times \vc{v}| = |\vc{v} \times \vc{u}| = |\vc{u}||\vc{v}|\sin\theta$, their direction is reversed.}

\newpage
\prop{NON-Associative}{}
\proofs{ Let $\vc{a}$ and $\vc{v}$ be two distinct non-zero vectors. Then we have:

\begin{align}
&\vc{a} \times (\vc{a} \times \vc{c}) \neq 0~\label{assoc:1} \\ 
&\underbrace{(\vc{a} \times \vc{a})}_{\ita{\scriptsize $0$ , since $\theta = 0$}}   \times \vc{c} = 0~\label{assoc:2}
\end{align}

\eqref{assoc:1} and \eqref{assoc:2} cannot both be true, hence we arrive at a contradiction.}

\prop{Distributive across scalar multiplication and addition}{}
\mymarginpar{addition proof beyond 1S's scope}

\proofs{ \\
$$\lambda (\vc{a} \times \vc{b}) = |\lambda\vc{a} \times \vc{b}| = |\vc{a} \times \lambda\vc{b}|$$
$$\vc{c}(\vc{a} + \vc{b}) = \vc{c} \times \vc{a} + \vc{c} \times \vc{b}$$}

\rem{Note that the dot and cross product do not distribute amongst themselves}
\proofs{ \begin{align}
& (\vc{a} \times \vc{b}) \cdot \vc{c}\ \ \  \ita{ Valid} \\
& \underbrace{(\vc{a} \cdot \vc{b})}_{\ita{yields a scalar}} \times \vc{c} \ \ \ \ita{ Invalid, scalar $\times$ vector not allowed}
\end{align}
}

\textbf{Application of the Cross Product}
\lecture{21}{01}{2019}
\ex{
\par{Three points A, B and C determine the plane P containing them. Find a criterion for a point P to lie on P in terms of A, B and C. \\ }

\par{It follows from (\ref{vectors:plane}), that we need to find the normal $n$ to the plane containing $A, B\text{ and }C$. And given that $\overrightarrow{AB}$ and $\overrightarrow{AC}$ lie in $P$:}

$$\vc{n} = \overrightarrow{AB} \times \overrightarrow{AC}$$

\par{So the criterion is:}

$$\overrightarrow{AP} \times \cdot \vc{n} = \overrightarrow{AP} \cdot (\overrightarrow{AB} \times \overrightarrow{AC}) = 0$$}

\newpage

\section{Counting Methods}

\subsection{The Multiplication Principle}

\defn{Multiplication Principle}{Let the joint experiment $ \theta $, represent an experiment, with $k$ possible outcomes, composed by two other distinct experiments $\lambda_1$ and $\lambda_2$ each witch $n_1$ and $n_2$ possible outcomes, respectively. Then, $k = n_1 \cdot n_2$}

\subsection{Combinations and Permutations}
\defn{Combinations}{For a collection of $n$ different objects, by selecting $r$ of them, the number of possible combinations where the \textbf{order does not matter}  is given by: \mymarginpar{Note the similarity of the formulas, since the order is irrelevant, we should expect the possible \# of combinations to decrease, hence higher denominator}
$$ {n \choose r} = \ \comb{n}{r} = \frac{n!}{(n-r)!r!}$$}

\defn{Permutations}{For a collection of $n$ different objects and $n$ spaces, the number of permutations is the number of possible ordered arrangements. It is given by $n!$}

\nota{More generally, when only wishing to select an $r$ number of those $n$ objects, where $0 \leq r \leq n$: $$\perm{n}{r} = \frac{n!}{(n-r)!}$$}

\rem{More generally still, for repeated objects ($n_1$ of type 1, \dots, $ n_t $ of type $t$): $$ \frac{n!}{n_1!
\times \dots \times n_t!}$$}

\lecture{22}{01}{2019}
\par{Note that we can obtain the permutations formula by looking at forming permutations of $r$ objects from$n$ as a two stage procedure:}

\begin{enumerate}
	\item Choose any combination of $r$ objects: $\comb{n}{r}$
	\item Order the $r$ objects: $r!$
\end{enumerate}

\textbf{Properties of $n \choose r$}

\prop{ For $n \in \n$ and $ r = 0,1,\dots$: $$ { n \choose n-r} = {n \choose r}$$~\label{choose:1}}

\proofs{ \begin{align*}
{n \choose n-r} & = \frac{n!}{(n-(n-r))!(n-r)! } \\ & = \frac{n!}{r! (n-r)!} \\ & = {n \choose r}
\end{align*}}

\ex{Determine, as efficiently as possible, the following:

$$ {n \choose 0} , {n \choose 1} , {n \choose 2} , {n \choose 3} , {n \choose 4} , {n \choose 5}\\ $$

\par{By using the symmetry which follows from (\ref{choose:1}) we have that:}

$$ {n \choose 0} = {n \choose 5} = 1 \ ; \ {n \choose 1} = {n \choose 4 } = 5 \ ; \ {n \choose 2} = {n \choose 3} = 10 $$
}


\subsection{Combinations subject to Constraints}

\begin{enumerate}
	\item Exclusion of $k$ objects: $${n \choose r}\bigg| _{\text{exclude }k} = {n-k \choose r}$$	
	\item Inclusion of $k$ objects: $${n \choose r}\bigg|_{\text{include }k} = {n-k \choose r-k}$$
	\item Complement: The number of combinations that do satisfy a constraint is the complement of the number that do not $$ \text{Combinations which satisfy the constraint } = \text{Total - Combinations which do not }$$
\end{enumerate}

\newpage	
\subsection{Pascal's Triangle}
\lecture{28}{01}{2019}

\par{The pascal's triangle is formed by setting the edges to $1$, and generating numbers for each row by summing the two numbers immediately above them. So that, for each row $n$, each entry represents choosing $n$ objects from $ 0 \to n$ }

$$
\begin{tabular}{rccccccccccccc}
$n=0$:&    &    &    &    &    &    &  1\\\noalign{\smallskip\smallskip}
$n=1$:&    &    &    &    &    &  1 &    &  1\\\noalign{\smallskip\smallskip}
$n=2$:&    &    &    &    &  1 &    &  2 &    &  1\\\noalign{\smallskip\smallskip}
$n=3$:&    &    &    &  1 &    &  3 &    &  3 &    &  1\\\noalign{\smallskip\smallskip}
$n=4$:&    &    &  1 &    &  4 &    &  6 &    &  4 &    &  1\\\noalign{\smallskip\smallskip}
$n=5$:&    &  1 &    &  5 &    & 10 &    & 10 &    &  5 &    &  1\\\noalign{\smallskip\smallskip}
$n=6$:&  1 &    &  6 &    & 15 &    & 20 &    & 15 &    &  6 &    &  1\\\noalign{\smallskip\smallskip}
\end{tabular}$$

\par{This construction relies on the following:}
 
\prop{For $n \in \n \text{ and } r = 1, 2, . . . , n,$ $$ {n+1 \choose r} = {n \choose r-1} + {n \choose r}}

\proofs{}
\mymarginpar{TODO: enquire about the exclusion bit of the proof}







%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Logical Matters \& Proof}

\defn{Direct Proof}{It consists of an argument that starts from the hypothesis and by a sequence of logical steps ends at the conclusion}

\rem{A common misconception is starting from the conclusion and finding something "true", by using both sides of the equation simultaneously}

\ex{Prove that the product of two odd integers is also odd}

\proofs{ Let $a, b$ be arbitrary odd integers. Then a $ a = 2k + 1$ and $b = 2l + 1$, for some $k, l \in \z$. Hence, \\

\begin{align*}
	ab &= (2k + 1)(2l + 1) \\
	&= 4kl + 2k + 2l + 1 \\
	&= 2(2kl + k + l) + 1
\end{align*}

Therefore, since $2kl + k + l \in \z$, $ab$ is odd.}

\newpage
\nocite{*}
\printbibliography



\end{document}
